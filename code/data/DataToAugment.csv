titles,Resolution,ID
Survey on Semantic Stereo Matching / Semantic Depth Estimation,"Stereo matching is one of the widely used techniques for inferring depth from
stereo images owing to its robustness and speed. It has become one of the major
topics of research since it finds its applications in autonomous driving,
robotic navigation, 3D reconstruction, and many other fields. Finding pixel
correspondences in non-textured, occluded and reflective areas is the major
challenge in stereo matching. Recent developments have shown that semantic cues
from image segmentation can be used to improve the results of stereo matching.
Many deep neural network architectures have been proposed to leverage the
advantages of semantic segmentation in stereo matching. This paper aims to give
a comparison among the state of art networks both in terms of accuracy and in
terms of speed which are of higher importance in real-time applications.","['cs.CV', 'cs.LG']"
FUTURE-AI: Guiding Principles and Consensus Recommendations for Trustworthy Artificial Intelligence in Future Medical Imaging,"The recent advancements in artificial intelligence (AI) combined with the
extensive amount of data generated by today's clinical systems, has led to the
development of imaging AI solutions across the whole value chain of medical
imaging, including image reconstruction, medical image segmentation,
image-based diagnosis and treatment planning. Notwithstanding the successes and
future potential of AI in medical imaging, many stakeholders are concerned of
the potential risks and ethical implications of imaging AI solutions, which are
perceived as complex, opaque, and difficult to comprehend, utilise, and trust
in critical clinical applications. Despite these concerns and risks, there are
currently no concrete guidelines and best practices for guiding future AI
developments in medical imaging towards increased trust, safety and adoption.
To bridge this gap, this paper introduces a careful selection of guiding
principles drawn from the accumulated experiences, consensus, and best
practices from five large European projects on AI in Health Imaging. These
guiding principles are named FUTURE-AI and its building blocks consist of (i)
Fairness, (ii) Universality, (iii) Traceability, (iv) Usability, (v) Robustness
and (vi) Explainability. In a step-by-step approach, these guidelines are
further translated into a framework of concrete recommendations for specifying,
developing, evaluating, and deploying technically, clinically and ethically
trustworthy AI solutions into clinical practice.","['cs.CV', 'cs.AI', 'cs.LG']"
Enforcing Mutual Consistency of Hard Regions for Semi-supervised Medical Image Segmentation,"In this paper, we proposed a novel mutual consistency network (MC-Net+) to
effectively exploit the unlabeled hard regions for semi-supervised medical
image segmentation. The MC-Net+ model is motivated by the observation that deep
models trained with limited annotations are prone to output highly uncertain
and easily mis-classified predictions in the ambiguous regions (e.g. adhesive
edges or thin branches) for the image segmentation task. Leveraging these
region-level challenging samples can make the semi-supervised segmentation
model training more effective. Therefore, our proposed MC-Net+ model consists
of two new designs. First, the model contains one shared encoder and multiple
sightly different decoders (i.e. using different up-sampling strategies). The
statistical discrepancy of multiple decoders' outputs is computed to denote the
model's uncertainty, which indicates the unlabeled hard regions. Second, a new
mutual consistency constraint is enforced between one decoder's probability
output and other decoders' soft pseudo labels. In this way, we minimize the
model's uncertainty during training and force the model to generate invariant
and low-entropy results in such challenging areas of unlabeled data, in order
to learn a generalized feature representation. We compared the segmentation
results of the MC-Net+ with five state-of-the-art semi-supervised approaches on
three public medical datasets. Extension experiments with two common
semi-supervised settings demonstrate the superior performance of our model over
other existing methods, which sets a new state of the art for semi-supervised
medical image segmentation.","['cs.CV', 'cs.AI']"
Parameter Decoupling Strategy for Semi-supervised 3D Left Atrium Segmentation,"Consistency training has proven to be an advanced semi-supervised framework
and achieved promising results in medical image segmentation tasks through
enforcing an invariance of the predictions over different views of the inputs.
However, with the iterative updating of model parameters, the models would tend
to reach a coupled state and eventually lose the ability to exploit unlabeled
data. To address the issue, we present a novel semi-supervised segmentation
model based on parameter decoupling strategy to encourage consistent
predictions from diverse views. Specifically, we first adopt a two-branch
network to simultaneously produce predictions for each image. During the
training process, we decouple the two prediction branch parameters by quadratic
cosine distance to construct different views in latent space. Based on this,
the feature extractor is constrained to encourage the consistency of
probability maps generated by classifiers under diversified features. In the
overall training process, the parameters of feature extractor and classifiers
are updated alternately by consistency regularization operation and decoupling
operation to gradually improve the generalization performance of the model. Our
method has achieved a competitive result over the state-of-the-art
semi-supervised methods on the Atrial Segmentation Challenge dataset,
demonstrating the effectiveness of our framework. Code is available at
https://github.com/BX0903/PDC.",['cs.CV']
Background-Foreground Segmentation for Interior Sensing in Automotive Industry,"To ensure safety in automated driving, the correct perception of the
situation inside the car is as important as its environment. Thus, seat
occupancy detection and classification of detected instances play an important
role in interior sensing. By the knowledge of the seat occupancy status, it is
possible to, e.g., automate the airbag deployment control. Furthermore, the
presence of a driver, which is necessary for partially automated driving cars
at the automation levels two to four can be verified. In this work, we compare
different statistical methods from the field of image segmentation to approach
the problem of background-foreground segmentation in camera based interior
sensing. In the recent years, several methods based on different techniques
have been developed and applied to images or videos from different
applications. The peculiarity of the given scenarios of interior sensing is,
that the foreground instances and the background both contain static as well as
dynamic elements. In data considered in this work, even the camera position is
not completely fixed. We review and benchmark three different methods ranging,
i.e., Gaussian Mixture Models (GMM), Morphological Snakes and a deep neural
network, namely a Mask R-CNN. In particular, the limitations of the classical
methods, GMM and Morphological Snakes, for interior sensing are shown.
Furthermore, it turns, that it is possible to overcome these limitations by
deep learning, e.g.\ using a Mask R-CNN. Although only a small amount of ground
truth data was available for training, we enabled the Mask R-CNN to produce
high quality background-foreground masks via transfer learning. Moreover, we
demonstrate that certain augmentation as well as pre- and post-processing
methods further enhance the performance of the investigated methods.","['cs.CV', 'cs.LG']"
EdgeFlow: Achieving Practical Interactive Segmentation with Edge-Guided Flow,"High-quality training data play a key role in image segmentation tasks.
Usually, pixel-level annotations are expensive, laborious and time-consuming
for the large volume of training data. To reduce labelling cost and improve
segmentation quality, interactive segmentation methods have been proposed,
which provide the result with just a few clicks. However, their performance
does not meet the requirements of practical segmentation tasks in terms of
speed and accuracy. In this work, we propose EdgeFlow, a novel architecture
that fully utilizes interactive information of user clicks with edge-guided
flow. Our method achieves state-of-the-art performance without any
post-processing or iterative optimization scheme. Comprehensive experiments on
benchmarks also demonstrate the superiority of our method. In addition, with
the proposed method, we develop an efficient interactive segmentation tool for
practical data annotation tasks. The source code and tool is avaliable at
https://github.com/PaddlePaddle/PaddleSeg.","['cs.CV', 'cs.HC']"
Efficient Hybrid Transformer: Learning Global-local Context for Urban Sence Segmentation,"Semantic segmentation of fine-resolution urban scene images plays a vital
role in extensive practical applications, such as land cover mapping, urban
change detection, environmental protection and economic assessment. Driven by
rapid developments in deep learning technologies, convolutional neural networks
(CNNs) have dominated the semantic segmentation task for many years.
Convolutional neural networks adopt hierarchical feature representation and
have strong local context extraction. However, the local property of the
convolution layer limits the network from capturing global information that is
crucial for improving fine-resolution image segmentation. Recently, Transformer
comprise a hot topic in the computer vision domain. Vision Transformer
demonstrates the great capability of global information modelling, boosting
many vision tasks, such as image classification, object detection and
especially semantic segmentation. In this paper, we propose an efficient hybrid
Transformer (EHT) for semantic segmentation of urban scene images. EHT takes
advantage of CNNs and Transformer, learning global-local context to strengthen
the feature representation. Extensive experiments demonstrate that EHT has
higher efficiency with competitive accuracy compared with state-of-the-art
benchmark methods. Specifically, the proposed EHT achieves a 67.0% mIoU on the
UAVid test set and outperforms other lightweight models significantly. The code
will be available soon.",['cs.CV']
Towards to Robust and Generalized Medical Image Segmentation Framework,"To mitigate the radiologist's workload, computer-aided diagnosis with the
capability to review and analyze medical images is gradually deployed. Deep
learning-based region of interest segmentation is among the most exciting use
cases. However, this paradigm is restricted in real-world clinical applications
due to poor robustness and generalization. The issue is more sinister with a
lack of training data. In this paper, we address the challenge from the
representation learning point of view. We investigate that the collapsed
representations, as one of the main reasons which caused poor robustness and
generalization, could be avoided through transfer learning. Therefore, we
propose a novel two-stage framework for robust generalized segmentation. In
particular, an unsupervised Tile-wise AutoEncoder (T-AE) pretraining
architecture is coined to learn meaningful representation for improving the
generalization and robustness of the downstream tasks. Furthermore, the learned
knowledge is transferred to the segmentation benchmark. Coupled with an image
reconstruction network, the representation keeps to be decoded, encouraging the
model to capture more semantic features. Experiments of lung segmentation on
multi chest X-ray datasets are conducted. Empirically, the related experimental
results demonstrate the superior generalization capability of the proposed
framework on unseen domains in terms of high performance and robustness to
corruption, especially under the scenario of the limited training data.","['cs.CV', 'cs.AI']"
Semi-supervised Meta-learning with Disentanglement for Domain-generalised Medical Image Segmentation,"Generalising deep models to new data from new centres (termed here domains)
remains a challenge. This is largely attributed to shifts in data statistics
(domain shifts) between source and unseen domains. Recently, gradient-based
meta-learning approaches where the training data are split into meta-train and
meta-test sets to simulate and handle the domain shifts during training have
shown improved generalisation performance. However, the current fully
supervised meta-learning approaches are not scalable for medical image
segmentation, where large effort is required to create pixel-wise annotations.
Meanwhile, in a low data regime, the simulated domain shifts may not
approximate the true domain shifts well across source and unseen domains. To
address this problem, we propose a novel semi-supervised meta-learning
framework with disentanglement. We explicitly model the representations related
to domain shifts. Disentangling the representations and combining them to
reconstruct the input image allows unlabeled data to be used to better
approximate the true domain shifts for meta-learning. Hence, the model can
achieve better generalisation performance, especially when there is a limited
amount of labeled data. Experiments show that the proposed method is robust on
different segmentation tasks and achieves state-of-the-art generalisation
performance on two public benchmarks.",['cs.CV']
Semi-supervised Contrastive Learning for Label-efficient Medical Image Segmentation,"The success of deep learning methods in medical image segmentation tasks
heavily depends on a large amount of labeled data to supervise the training. On
the other hand, the annotation of biomedical images requires domain knowledge
and can be laborious. Recently, contrastive learning has demonstrated great
potential in learning latent representation of images even without any label.
Existing works have explored its application to biomedical image segmentation
where only a small portion of data is labeled, through a pre-training phase
based on self-supervised contrastive learning without using any labels followed
by a supervised fine-tuning phase on the labeled portion of data only. In this
paper, we establish that by including the limited label in formation in the
pre-training phase, it is possible to boost the performance of contrastive
learning. We propose a supervised local contrastive loss that leverages limited
pixel-wise annotation to force pixels with the same label to gather around in
the embedding space. Such loss needs pixel-wise computation which can be
expensive for large images, and we further propose two strategies, downsampling
and block division, to address the issue. We evaluate our methods on two public
biomedical image datasets of different modalities. With different amounts of
labeled data, our methods consistently outperform the state-of-the-art
contrast-based methods and other semi-supervised learning techniques.",['cs.CV']
Direct Estimation of Appearance Models for Segmentation,"Image segmentation algorithms often depend on appearance models that
characterize the distribution of pixel values in different image regions. We
describe a new approach for estimating appearance models directly from an
image, without explicit consideration of the pixels that make up each region.
Our approach is based on novel algebraic expressions that relate local image
statistics to the appearance of spatially coherent regions. We describe two
algorithms that can use the aforementioned algebraic expressions to estimate
appearance models directly from an image. The first algorithm solves a system
of linear and quadratic equations using a least squares formulation. The second
algorithm is a spectral method based on an eigenvector computation. We present
experimental results that demonstrate the proposed methods work well in
practice and lead to effective image segmentation algorithms.","['cs.CV', '68U10, 62M05, 62H30, 65C20']"
MISSFormer: An Effective Medical Image Segmentation Transformer,"The CNN-based methods have achieved impressive results in medical image
segmentation, but it failed to capture the long-range dependencies due to the
inherent locality of convolution operation. Transformer-based methods are
popular in vision tasks recently because of its capacity of long-range
dependencies and get a promising performance. However, it lacks in modeling
local context, although some works attempted to embed convolutional layer to
overcome this problem and achieved some improvement, but it makes the feature
inconsistent and fails to leverage the natural multi-scale features of
hierarchical transformer, which limit the performance of models. In this paper,
taking medical image segmentation as an example, we present MISSFormer, an
effective and powerful Medical Image Segmentation tranSFormer. MISSFormer is a
hierarchical encoder-decoder network and has two appealing designs: 1) A feed
forward network is redesigned with the proposed Enhanced Transformer Block,
which makes features aligned adaptively and enhances the long-range
dependencies and local context. 2) We proposed Enhanced Transformer Context
Bridge, a context bridge with the enhanced transformer block to model the
long-range dependencies and local context of multi-scale features generated by
our hierarchical transformer encoder. Driven by these two designs, the
MISSFormer shows strong capacity to capture more valuable dependencies and
context in medical image segmentation. The experiments on multi-organ and
cardiac segmentation tasks demonstrate the superiority, effectiveness and
robustness of our MISSFormer, the exprimental results of MISSFormer trained
from scratch even outperforms state-of-the-art methods pretrained on ImageNet,
and the core designs can be generalized to other visual segmentation tasks. The
code will be released in Github.",['cs.CV']
Neural Architecture Search in operational context: a remote sensing case-study,"Deep learning has become in recent years a cornerstone tool fueling key
innovations in the industry, such as autonomous driving. To attain good
performances, the neural network architecture used for a given application must
be chosen with care. These architectures are often handcrafted and therefore
prone to human biases and sub-optimal selection. Neural Architecture Search
(NAS) is a framework introduced to mitigate such risks by jointly optimizing
the network architectures and its weights. Albeit its novelty, it was applied
on complex tasks with significant results - e.g. semantic image segmentation.
In this technical paper, we aim to evaluate its ability to tackle a challenging
operational task: semantic segmentation of objects of interest in satellite
imagery. Designing a NAS framework is not trivial and has strong dependencies
to hardware constraints. We therefore motivate our NAS approach selection and
provide corresponding implementation details. We also present novel ideas to
carry out other such use-case studies.","['cs.CV', 'cs.NE']"
Patch-based medical image segmentation using Quantum Tensor Networks,"Tensor networks are efficient factorisations of high dimensional tensors into
a network of lower order tensors. They have been most commonly used to model
entanglement in quantum many-body systems and more recently are witnessing
increased applications in supervised machine learning. In this work, we
formulate image segmentation in a supervised setting with tensor networks. The
key idea is to first lift the pixels in image patches to exponentially high
dimensional feature spaces and using a linear decision hyper-plane to classify
the input pixels into foreground and background classes. The high dimensional
linear model itself is approximated using the matrix product state (MPS) tensor
network. The MPS is weight-shared between the non-overlapping image patches
resulting in our strided tensor network model. The performance of the proposed
model is evaluated on three 2D- and one 3D- biomedical imaging datasets. The
performance of the proposed tensor network segmentation model is compared with
relevant baseline methods. In the 2D experiments, the tensor network model
yeilds competitive performance compared to the baseline methods while being
more resource efficient.",['cs.CV']
Combo Loss: Handling Input and Output Imbalance in Multi-Organ Segmentation,"Simultaneous segmentation of multiple organs from different medical imaging
modalities is a crucial task as it can be utilized for computer-aided
diagnosis, computer-assisted surgery, and therapy planning. Thanks to the
recent advances in deep learning, several deep neural networks for medical
image segmentation have been introduced successfully for this purpose. In this
paper, we focus on learning a deep multi-organ segmentation network that labels
voxels. In particular, we examine the critical choice of a loss function in
order to handle the notorious imbalance problem that plagues both the input and
output of a learning model. The input imbalance refers to the class-imbalance
in the input training samples (i.e., small foreground objects embedded in an
abundance of background voxels, as well as organs of varying sizes). The output
imbalance refers to the imbalance between the false positives and false
negatives of the inference model. In order to tackle both types of imbalance
during training and inference, we introduce a new curriculum learning based
loss function. Specifically, we leverage Dice similarity coefficient to deter
model parameters from being held at bad local minima and at the same time
gradually learn better model parameters by penalizing for false
positives/negatives using a cross entropy term. We evaluated the proposed loss
function on three datasets: whole body positron emission tomography (PET) scans
with 5 target organs, magnetic resonance imaging (MRI) prostate scans, and
ultrasound echocardigraphy images with a single target organ i.e., left
ventricular. We show that a simple network architecture with the proposed
integrative loss function can outperform state-of-the-art methods and results
of the competing methods can be improved when our proposed loss is used.",['cs.CV']
POPCORN: Progressive Pseudo-labeling with Consistency Regularization and Neighboring,"Semi-supervised learning (SSL) uses unlabeled data to compensate for the
scarcity of annotated images and the lack of method generalization to unseen
domains, two usual problems in medical segmentation tasks. In this work, we
propose POPCORN, a novel method combining consistency regularization and
pseudo-labeling designed for image segmentation. The proposed framework uses
high-level regularization to constrain our segmentation model to use similar
latent features for images with similar segmentations. POPCORN estimates a
proximity graph to select data from easiest ones to more difficult ones, in
order to ensure accurate pseudo-labeling and to limit confirmation bias.
Applied to multiple sclerosis lesion segmentation, our method demonstrates
competitive results compared to other state-of-the-art SSL strategies.",['cs.CV']
HCDG: A Hierarchical Consistency Framework for Domain Generalization on Medical Image Segmentation,"Modern deep neural networks struggle to transfer knowledge and generalize
across domains when deploying to real-world applications. Domain generalization
(DG) aims to learn a universal representation from multiple source domains to
improve the network generalization ability on unseen target domains. Previous
DG methods mostly focus on the data-level consistency scheme to advance the
generalization capability of deep networks, without considering the synergistic
regularization of different consistency schemes. In this paper, we present a
novel Hierarchical Consistency framework for Domain Generalization (HCDG) by
ensembling Extrinsic Consistency and Intrinsic Consistency. Particularly, for
Extrinsic Consistency, we leverage the knowledge across multiple source domains
to enforce data-level consistency. Also, we design a novel Amplitude
Gaussian-mixing strategy for Fourier-based data augmentation to enhance such
consistency. For Intrinsic Consistency, we perform task-level consistency for
the same instance under the dual-task form. We evaluate the proposed HCDG
framework on two medical image segmentation tasks, i.e., optic cup/disc
segmentation on fundus images and prostate MRI segmentation. Extensive
experimental results manifest the effectiveness and versatility of our HCDG
framework. Code will be available once accept.",['cs.CV']
Pyramid Medical Transformer for Medical Image Segmentation,"Deep neural networks have been a prevailing technique in the field of medical
image processing. However, the most popular convolutional neural networks
(CNNs) based methods for medical image segmentation are imperfect because they
model long-range dependencies by stacking layers or enlarging filters.
Transformers and the self-attention mechanism are recently proposed to
effectively learn long-range dependencies by modeling all pairs of word-to-word
attention regardless of their positions. The idea has also been extended to the
computer vision field by creating and treating image patches as embeddings.
Considering the computation complexity for whole image self-attention, current
transformer-based models settle for a rigid partitioning scheme that
potentially loses informative relations. Besides, current medical transformers
model global context on full resolution images, leading to unnecessary
computation costs. To address these issues, we developed a novel method to
integrate multi-scale attention and CNN feature extraction using a pyramidal
network architecture, namely Pyramid Medical Transformer (PMTrans). The PMTrans
captured multi-range relations by working on multi-resolution images. An
adaptive partitioning scheme was implemented to retain informative relations
and to access different receptive fields efficiently. Experimental results on
three medical image datasets (gland segmentation, MoNuSeg, and HECKTOR
datasets) showed that PMTrans outperformed the latest CNN-based and
transformer-based models for medical image segmentation.",['cs.CV']
Temporally Coherent Person Matting Trained on Fake-Motion Dataset,"We propose a novel neural-network-based method to perform matting of videos
depicting people that does not require additional user input such as trimaps.
Our architecture achieves temporal stability of the resulting alpha mattes by
using motion-estimation-based smoothing of image-segmentation algorithm
outputs, combined with convolutional-LSTM modules on U-Net skip connections.
  We also propose a fake-motion algorithm that generates training clips for the
video-matting network given photos with ground-truth alpha mattes and
background videos. We apply random motion to photos and their mattes to
simulate movement one would find in real videos and composite the result with
the background clips. It lets us train a deep neural network operating on
videos in an absence of a large annotated video dataset and provides
ground-truth training-clip foreground optical flow for use in loss functions.",['cs.CV']
